---
title: 'Guided Project: Creating An Efficient Data Analysis Workflow, Part 2'
author: "Thais Lovisi"
date: "2023-01-07"
output: html_document
---

## Introduction

For the same data set from the previous project. The company has provided us more data on some of its 2019 book sales, and it wants us to extract some usable knowledge from it. It launched a new program encouraging customers to buy more books on July 1st, 2019, and it wants to know if this new program was successful at increasing sales and improving review quality. 


## Step 1 - Setup

Loading libraries

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library (lubridate)
```

Uploading original data set

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
sales_data <- read_csv("sales2019.csv")
```

## Step 2 - Data Exploration

```{r}
dim(sales_data)
names <- as.data.frame(colnames(sales_data))
for (c in colnames(sales_data)){
  paste0(c, " : ", typeof(sales_data[[c]])) %>% print
}
```

## Step 3 - Handling Missing Data

There is any NA value? 

```{r}
for (c in colnames(sales_data)){
  for (i in 1:nrow(sales_data)){
    if (is.na(sales_data[i,c])){
      paste0("There is a NA in ", c, " ") %>% print
      break
    }else{
      next
}
  }
}
```

### Handling missing data

The user_submitted_review column contains some `NA` values. In this case we will be removing those columns completely.

```{r}
clean_sales_data <- sales_data %>% filter(!is.na(user_submitted_review))
dim(clean_sales_data)
```
For total_purchased we can replace the NA on var total_purchased by the mean value ( handle it with imputation.)
  
  Calculate the mean value

```{r}
purchase_mean <- clean_sales_data %>% 
  filter(!is.na(total_purchased)) %>% 
  pull(total_purchased) %>% 
  mean
```

  Create a new colunm with the replacement for NA
WARNING: Never Overwrite col. (Good practice)

```{r}
clean_sales_data <- clean_sales_data %>% 
  mutate(
    imputed_purchase = if_else(is.na(total_purchased),purchase_mean,total_purchased)
  )
```

## Step 3 - Processing Review Data

Identify and Rewrite unique words

```{r}
unique_words <- clean_sales_data %>% pull(user_submitted_review) %>% unique() # identifying

is_positive <- function(review) { # identifying words of a positive review
  review_positive = case_when(
    str_detect(review, "Awesome") ~ TRUE,
    str_detect(review, "OK") ~ TRUE,
    str_detect(review, "Never") ~ TRUE,
    str_detect(review, "a lot") ~ TRUE,
    TRUE ~ FALSE # The review did not contain any of the above phrases
  )
}

clean_sales_data <- clean_sales_data %>% #Rewriting it in a new colunm called positive_Review
  mutate(
   positive_Review = unlist(map(user_submitted_review, is_positive))
  )
  
```

## Step 4 - Detecting if sales data imputed before or after the start of the new sales plan:

```{r}
clean_sales_data <- clean_sales_data %>% 
  mutate(
    date_status = if_else(mdy(date) < ymd("2019/07/01"), "Pre", "Post")
  )
```

## Step 5 - Comparing Variables

## Group variable in accordance with pre or post sales changes

```{r echo=TRUE}
clean_sales_data %>% 
  group_by(date_status) %>%
     summarise(
      books_purchased = sum(imputed_purchase)
      )

```
### Comparing Book Sales Within Customer Type
```{r echo=TRUE}

clean_sales_data %>% 
  group_by(date_status, customer_type) %>%
  summarise(
    books_purchased = sum(imputed_purchase)
  )
```
It doesn't seem that the program has increased sales. Maybe there were certain books that increased in sales?

### Comparing Book Sales Within title Type

```{r}

clean_sales_data %>% 
  group_by(date_status, title) %>%
  summarise(
    books_purchased = sum(imputed_purchase)
  )

```

Based on the table, it looks like businesses started purchasing more books after the program! There was actually a drop in individual sales.


### Comparing Review Sentiment Between Pre- and Post-Program Sales

```{r}

clean_sales_data %>% 
  group_by(date_status, positive_Review) %>%
  summarise(
    books_purchased = sum(imputed_purchase)
  )
```

There's slightly more reviews before the program, but this difference seems negigible.